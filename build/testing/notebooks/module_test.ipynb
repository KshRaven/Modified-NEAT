{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from build import Genome, Config\n",
    "from build.util.datetime import eta\n",
    "\n",
    "import build as neat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time as clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "DTYPE = torch.float64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NeatModule.__init__() got multiple values for argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m test_model \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\u001B[43mneat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNeatModule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mxavier_norm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mTypeError\u001B[0m: NeatModule.__init__() got multiple values for argument 'device'"
     ]
    }
   ],
   "source": [
    "test_model = nn.Sequential(neat.NeatModule(3, 3, 10, 128, 3, 0, True, device=DEVICE, dtype=DTYPE, init_type='xavier_norm'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_modules = [m for m in test_model.modules() if isinstance(m, neat.NeatModule)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_config = neat.Config('test')\n",
    "test_config.species.compatibility_threshold = 0.5\n",
    "test_config.general.fitness_criterion = 'max'\n",
    "test_config.reproduction.elitism = 5\n",
    "test_config.save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_population = neat.Population(test_model, test_config, init_rep=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_population.pop_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_input = torch.rand(200, 3).to(DEVICE, DTYPE)\n",
    "test_output = test_input # torch.rand(100, 3).to(DEVICE, DTYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([100, 1, 128]), torch.Size([100, 1, 128]))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(100, 1, 7)\n",
    "b = torch.rand(100, 7, 128)\n",
    "x = torch.matmul(a, b)\n",
    "c = torch.rand(100, 128, 128)\n",
    "y = torch.matmul(x, c)\n",
    "x.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.rand(20, 24, 1)\n",
    "b = torch.mean(a, 1, True)\n",
    "x = a - b\n",
    "a.shape, b.shape, x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.rand(10, 10)\n",
    "torch.max(x, 0)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.randn(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1 - (torch.randint_like(torch.randn(10), 2) * 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0067,  0.0037,  0.0062, -0.0028, -0.0089, -0.0063, -0.0042, -0.0043,\n         0.0077, -0.0069])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mean = torch.zeros((10,))\n",
    "test_std = torch.full((10,), 0.01)\n",
    "torch.normal(test_mean, test_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_pred = test_model(test_input[:2])\n",
    "    print(test_pred.shape, test_input[:2].shape, ) #torch.mean(test_pred, dim=(0, 2)).shape, test_output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3734, 0.4537, 0.1525, 0.1401, 0.4220, 0.3056, 0.5086, 0.7334, 0.7414,\n",
      "        0.5335], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    test_pred = test_model(test_input).cpu()\n",
    "    test_targ = test_output.unsqueeze(0).expand(10, -1, -1).cpu()\n",
    "    print(torch.mean((test_targ - test_pred) ** 2, dim=(-1, -2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "test_opt = optim.Adam(test_model.parameters(), lr=1e-6, weight_decay=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def evaluate(genomes: dict[int, Genome], config: Config):\n",
    "    test_model.cuda()\n",
    "    # with torch.no_grad():\n",
    "    mse = None\n",
    "    ts = clock.perf_counter()\n",
    "    units_total = 1000\n",
    "    units_done = 0\n",
    "    torch.cuda.empty_cache()\n",
    "    for epoch in range(1000):\n",
    "        units_done += 1\n",
    "\n",
    "        pred = test_model(test_input)\n",
    "        targ = test_output.unsqueeze(0).expand(*pred.shape)\n",
    "        loss = F.mse_loss(targ, pred)\n",
    "\n",
    "        test_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(test_model.parameters(), 1.0)\n",
    "        test_opt.step()\n",
    "\n",
    "        if epoch == 999:\n",
    "            mse = torch.mean((targ - pred) ** 2, dim=(-1, -2))\n",
    "\n",
    "        eta(ts, units_done, units_total, 'getting execution')\n",
    "    print(f\"\\nmin = {torch.min(mse, dim=0)}             \")\n",
    "    torch.cuda.empty_cache()\n",
    "    test_model.cpu()\n",
    "\n",
    "    mapping = {genome.index: genome for genome in genomes.values()}\n",
    "    for index, genome in mapping.items():\n",
    "        # genome.fitness = 1\n",
    "        genome.fitness = -mse[index].item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_population.species.species[1].representative.gid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** \u001B[93m\u001B[1mRunning generation 0\u001B[0m ****** \n",
      "\n",
      "Executing fitness function <function evaluate at 0x00000232C5676A20> on Population\n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.1365, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(3, device='cuda:0'))             \n",
      "Updating Population\n",
      "Population's average fitness: -0.42929 std_dev: 0.19441\n",
      "Best fitness: -0.13646 - size: (388, 33539) - species 1 - id 4\n",
      "Getting Species\n",
      "Finsished speciating in 0 sec% eta=0sec\n",
      "Mean genetic distance \u001B[93m\u001B[1m0.000\u001B[0m, standard deviation \u001B[93m\u001B[1m0.000\u001B[0m\n",
      "Population of 10 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "   1    0    10       --       --     0\n",
      "Total extinctions: 0\n",
      "Generation time: 4.073 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": "<build.genome.Genome at 0x232903451d0>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_population.run(evaluate, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<function numpy.amax(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_population.fitness_criterion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0096, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0095, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0095, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0094, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0094, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0093, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0093, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0092, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0092, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n",
      "getting execution: progress=100% eta=0sec\n",
      "min = torch.return_types.min(\n",
      "values=tensor(0.0091, device='cuda:0', dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor(2, device='cuda:0'))             \n"
     ]
    }
   ],
   "source": [
    "for I in range(10):\n",
    "    evaluate(test_population.population, test_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9883, 0.4512, 0.2770],\n",
      "        [0.4544, 0.2295, 0.5954]], dtype=torch.float64)\n",
      "tensor([[0.9883, 0.4512, 0.2770],\n",
      "        [0.4544, 0.2295, 0.5954]], dtype=torch.float64)\n",
      "tensor([[[1.0096, 0.4558, 0.3095],\n",
      "         [0.3296, 0.2027, 0.4050]],\n",
      "\n",
      "        [[0.5454, 0.5022, 0.5358],\n",
      "         [0.4682, 0.5172, 0.4699]],\n",
      "\n",
      "        [[0.9845, 0.4393, 0.3095],\n",
      "         [0.4764, 0.2990, 0.4051]],\n",
      "\n",
      "        [[1.0092, 0.4559, 0.2853],\n",
      "         [0.3314, 0.2019, 0.5469]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_model.cuda()\n",
    "    test_pred = test_model(test_input[:2]).cpu()\n",
    "    o = [test_input[:2], test_output[:2], test_pred[[0, 1, test_population.best_genome.index, test_population.population[3].index]] ]\n",
    "    for p in o:\n",
    "        print(p.cpu())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}